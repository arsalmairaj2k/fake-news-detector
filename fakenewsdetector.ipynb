{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9aa27fa",
   "metadata": {},
   "source": [
    "### Preprocessing the Data (LIAR Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6582a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "import pandas as pd\n",
    "\n",
    "def load_liar_dataset():\n",
    "    \"\"\"\n",
    "    Load and prepare the LIAR dataset\n",
    "    \"\"\"\n",
    "    # Column names for the TSV file\n",
    "    columns = ['id', 'label', 'statement', 'subject', 'speaker', 'speaker_job', \n",
    "              'state_info', 'party_affiliation', 'barely_true_counts', \n",
    "              'false_counts', 'half_true_counts', 'mostly_true_counts', \n",
    "              'pants_on_fire_counts', 'context']\n",
    "    \n",
    "    try:\n",
    "        # Read the TSV file\n",
    "        df = pd.read_csv('train.tsv', sep='\\t', names=columns)\n",
    "        \n",
    "        # Convert to binary classification\n",
    "        label_map = {\n",
    "            'true': 1, 'mostly-true': 1, 'half-true': 1,\n",
    "            'barely-true': 0, 'false': 0, 'pants-fire': 0\n",
    "        }\n",
    "        df['label_binary'] = df['label'].map(label_map)\n",
    "        \n",
    "        print(\"Dataset Overview:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df[['statement', 'label', 'label_binary', 'speaker', 'context']].head())\n",
    "        print(\"\\nClass distribution (Binary):\")\n",
    "        print(df['label_binary'].value_counts(normalize=True))\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Dataset file not found. Please check if train.tsv exists in the current directory.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb87d51",
   "metadata": {},
   "source": [
    "### Pre-Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff4d0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess the text data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text preprocessing: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Prepare text and metadata features with memory optimization\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Processing text features...\")\n",
    "        # Process text in smaller chunks\n",
    "        chunk_size = 1000\n",
    "        processed_texts = []\n",
    "        \n",
    "        for i in range(0, len(df), chunk_size):\n",
    "            chunk = df['statement'].iloc[i:i+chunk_size]\n",
    "            processed_chunk = [preprocess_text(text) for text in chunk]\n",
    "            processed_texts.extend(processed_chunk)\n",
    "        \n",
    "        df['processed_statement'] = processed_texts\n",
    "        \n",
    "        # Initialize TF-IDF with memory-efficient parameters\n",
    "        tfidf = TfidfVectorizer(\n",
    "            max_features=5000,  # Fixed number of text features\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=3,\n",
    "            max_df=0.9,\n",
    "            strip_accents='unicode',\n",
    "            use_idf=True,\n",
    "            smooth_idf=True,\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "        \n",
    "        print(\"Vectorizing text...\")\n",
    "        text_features = tfidf.fit_transform(df['processed_statement'])\n",
    "        \n",
    "        print(\"Processing metadata features...\")\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        # Process categorical features (4 features)\n",
    "        categorical_columns = ['speaker', 'subject', 'party_affiliation', 'context']\n",
    "        encoded_features = []\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            encoded_col = le.fit_transform(df[col].astype(str))\n",
    "            encoded_features.append(encoded_col.reshape(-1, 1))\n",
    "        \n",
    "        # Process numerical features (5 features)\n",
    "        numerical_columns = [\n",
    "            'barely_true_counts', 'false_counts',\n",
    "            'half_true_counts', 'mostly_true_counts', \n",
    "            'pants_on_fire_counts'\n",
    "        ]\n",
    "        \n",
    "        # Scale numerical features\n",
    "        scaler = StandardScaler()\n",
    "        numerical_features = scaler.fit_transform(df[numerical_columns])\n",
    "        \n",
    "        # Calculate credibility score (1 feature)\n",
    "        credibility_score = (\n",
    "            (df['mostly_true_counts']) /\n",
    "            (df['false_counts'] + df['pants_on_fire_counts'] + 1)\n",
    "        ).values.reshape(-1, 1)\n",
    "        \n",
    "        print(\"Combining features...\")\n",
    "        # Convert sparse matrix to array and combine features\n",
    "        all_features = np.hstack(\n",
    "            [text_features.toarray()] + \n",
    "            encoded_features + \n",
    "            [numerical_features] +\n",
    "            [credibility_score]\n",
    "        )\n",
    "        \n",
    "        print(f\"Total features: {all_features.shape[1]}\")  # Should be 5010\n",
    "        return all_features, tfidf\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature preparation: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c17e4",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a97e2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"\n",
    "    Train the XGBoost model with focus on precision\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    # XGBoost parameters optimized for precision\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=200,          # More trees\n",
    "        learning_rate=0.05,        # Slower learning rate\n",
    "        max_depth=6,              # Slightly deeper trees\n",
    "        min_child_weight=2,       # More conservative splits\n",
    "        subsample=0.8,            # Prevent overfitting\n",
    "        colsample_bytree=0.8,     # Prevent overfitting\n",
    "        scale_pos_weight=1,       # Balance precision\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    # Train the model (simplified fit call)\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nPrecision Score (our priority metric):\")\n",
    "    print(precision_score(y_test, y_pred))\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa0b0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and vectorizer\n",
    "import joblib\n",
    "\n",
    "def save_model_and_vectorizer(model, vectorizer, model_path='fake_news_model.joblib', vectorizer_path='tfidf_vectorizer.joblib'):\n",
    "    \"\"\"\n",
    "    Save the trained model and vectorizer\n",
    "    \"\"\"\n",
    "    joblib.dump(model, model_path)\n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    print(f\"Vectorizer saved to {vectorizer_path}\")\n",
    "\n",
    "# Prediction function for new texts\n",
    "def predict_news(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict if a news text is fake or real\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess the text\n",
    "        processed_text = preprocess_text(text)\n",
    "        \n",
    "        # Transform using saved vectorizer\n",
    "        text_features = vectorizer.transform([processed_text]).toarray()\n",
    "        \n",
    "        # Add dummy metadata features (10 features to match training)\n",
    "        # - 4 categorical features (speaker, subject, party_affiliation, context)\n",
    "        # - 5 numerical features (barely_true_counts, false_counts, etc.)\n",
    "        # - 1 credibility score\n",
    "        dummy_metadata = np.zeros((1, 10))  # Create exactly 10 dummy features\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.hstack([text_features, dummy_metadata])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(combined_features)[0]\n",
    "        probability = model.predict_proba(combined_features)[0]\n",
    "        \n",
    "        return {\n",
    "            'prediction': 'True' if prediction == 1 else 'False',\n",
    "            'confidence': float(max(probability)),\n",
    "            'probabilities': {\n",
    "                'false': float(probability[0]),\n",
    "                'true': float(probability[1])\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {str(e)}\")\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'prediction': 'Error',\n",
    "            'confidence': 0.0,\n",
    "            'probabilities': {'false': 0.0, 'true': 0.0}\n",
    "        }\n",
    "\n",
    "# Test function\n",
    "def test_prediction_pipeline(model, vectorizer):\n",
    "    \"\"\"\n",
    "    Test the prediction pipeline with some example texts\n",
    "    \"\"\"\n",
    "    test_texts = [\n",
    "        \"The company exceeded quarterly earnings expectations with a 25% revenue growth.\",\n",
    "        \"Government officials deny any involvement in the controversial policy change.\",\n",
    "        \"Studies show that the new policy has had mixed results across different regions.\",\n",
    "        \"The CEO announced record profits despite market challenges.\",\n",
    "        \"Anonymous sources claim massive layoffs are planned for next month.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting prediction pipeline:\")\n",
    "    print(\"-\" * 50)\n",
    "    for text in test_texts:\n",
    "        try:\n",
    "            result = predict_news(text, model, vectorizer)\n",
    "            if 'error' in result:\n",
    "                print(f\"\\nError processing text: {text}\")\n",
    "                print(f\"Error message: {result['error']}\")\n",
    "            else:\n",
    "                print(f\"\\nText: {text}\")\n",
    "                print(f\"Prediction: {result['prediction']}\")\n",
    "                print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "                print(f\"True probability: {result['probabilities']['true']:.2%}\")\n",
    "                print(f\"False probability: {result['probabilities']['false']:.2%}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing text: {text}\")\n",
    "            print(f\"Error message: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa80117",
   "metadata": {},
   "source": [
    "### Main function & saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bedbd5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset Overview:\n",
      "--------------------------------------------------\n",
      "Total samples: 10240\n",
      "\n",
      "First few rows:\n",
      "                                           statement        label  \\\n",
      "0  Says the Annies List political group supports ...        false   \n",
      "1  When did the decline of coal start? It started...    half-true   \n",
      "2  Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
      "3  Health care reform legislation is likely to ma...        false   \n",
      "4  The economic turnaround started at the end of ...    half-true   \n",
      "\n",
      "   label_binary         speaker              context  \n",
      "0             0    dwayne-bohac             a mailer  \n",
      "1             1  scott-surovell      a floor speech.  \n",
      "2             1    barack-obama               Denver  \n",
      "3             0    blog-posting       a news release  \n",
      "4             1   charlie-crist  an interview on CNN  \n",
      "\n",
      "Class distribution (Binary):\n",
      "label_binary\n",
      "1    0.561719\n",
      "0    0.438281\n",
      "Name: proportion, dtype: float64\n",
      "Preparing features...\n",
      "Processing text features...\n",
      "Vectorizing text...\n",
      "Processing metadata features...\n",
      "Combining features...\n",
      "Total features: 5010\n",
      "Training model...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalmairaj/AISkillbridge/Class_4_5/myenv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [21:48:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67743\n",
      "[1]\tvalidation_0-logloss:0.66646\n",
      "[2]\tvalidation_0-logloss:0.65341\n",
      "[3]\tvalidation_0-logloss:0.64545\n",
      "[4]\tvalidation_0-logloss:0.63605\n",
      "[5]\tvalidation_0-logloss:0.62789\n",
      "[6]\tvalidation_0-logloss:0.62068\n",
      "[7]\tvalidation_0-logloss:0.61335\n",
      "[8]\tvalidation_0-logloss:0.60484\n",
      "[9]\tvalidation_0-logloss:0.59722\n",
      "[10]\tvalidation_0-logloss:0.59033\n",
      "[11]\tvalidation_0-logloss:0.58581\n",
      "[12]\tvalidation_0-logloss:0.57996\n",
      "[13]\tvalidation_0-logloss:0.57435\n",
      "[14]\tvalidation_0-logloss:0.57085\n",
      "[15]\tvalidation_0-logloss:0.56696\n",
      "[16]\tvalidation_0-logloss:0.56371\n",
      "[17]\tvalidation_0-logloss:0.56074\n",
      "[18]\tvalidation_0-logloss:0.55894\n",
      "[19]\tvalidation_0-logloss:0.55715\n",
      "[20]\tvalidation_0-logloss:0.55302\n",
      "[21]\tvalidation_0-logloss:0.54901\n",
      "[22]\tvalidation_0-logloss:0.54768\n",
      "[23]\tvalidation_0-logloss:0.54543\n",
      "[24]\tvalidation_0-logloss:0.54368\n",
      "[25]\tvalidation_0-logloss:0.54110\n",
      "[26]\tvalidation_0-logloss:0.53943\n",
      "[27]\tvalidation_0-logloss:0.53643\n",
      "[28]\tvalidation_0-logloss:0.53372\n",
      "[29]\tvalidation_0-logloss:0.53121\n",
      "[30]\tvalidation_0-logloss:0.52974\n",
      "[31]\tvalidation_0-logloss:0.52729\n",
      "[32]\tvalidation_0-logloss:0.52517\n",
      "[33]\tvalidation_0-logloss:0.52379\n",
      "[34]\tvalidation_0-logloss:0.52268\n",
      "[35]\tvalidation_0-logloss:0.52086\n",
      "[36]\tvalidation_0-logloss:0.52005\n",
      "[37]\tvalidation_0-logloss:0.51823\n",
      "[38]\tvalidation_0-logloss:0.51661\n",
      "[39]\tvalidation_0-logloss:0.51525\n",
      "[40]\tvalidation_0-logloss:0.51462\n",
      "[41]\tvalidation_0-logloss:0.51393\n",
      "[42]\tvalidation_0-logloss:0.51341\n",
      "[43]\tvalidation_0-logloss:0.51233\n",
      "[44]\tvalidation_0-logloss:0.51129\n",
      "[45]\tvalidation_0-logloss:0.51049\n",
      "[46]\tvalidation_0-logloss:0.50946\n",
      "[47]\tvalidation_0-logloss:0.50931\n",
      "[48]\tvalidation_0-logloss:0.50835\n",
      "[49]\tvalidation_0-logloss:0.50758\n",
      "[50]\tvalidation_0-logloss:0.50744\n",
      "[51]\tvalidation_0-logloss:0.50739\n",
      "[52]\tvalidation_0-logloss:0.50691\n",
      "[53]\tvalidation_0-logloss:0.50669\n",
      "[54]\tvalidation_0-logloss:0.50630\n",
      "[55]\tvalidation_0-logloss:0.50608\n",
      "[56]\tvalidation_0-logloss:0.50559\n",
      "[57]\tvalidation_0-logloss:0.50559\n",
      "[58]\tvalidation_0-logloss:0.50543\n",
      "[59]\tvalidation_0-logloss:0.50539\n",
      "[60]\tvalidation_0-logloss:0.50539\n",
      "[61]\tvalidation_0-logloss:0.50521\n",
      "[62]\tvalidation_0-logloss:0.50489\n",
      "[63]\tvalidation_0-logloss:0.50499\n",
      "[64]\tvalidation_0-logloss:0.50484\n",
      "[65]\tvalidation_0-logloss:0.50479\n",
      "[66]\tvalidation_0-logloss:0.50437\n",
      "[67]\tvalidation_0-logloss:0.50415\n",
      "[68]\tvalidation_0-logloss:0.50389\n",
      "[69]\tvalidation_0-logloss:0.50357\n",
      "[70]\tvalidation_0-logloss:0.50296\n",
      "[71]\tvalidation_0-logloss:0.50234\n",
      "[72]\tvalidation_0-logloss:0.50237\n",
      "[73]\tvalidation_0-logloss:0.50235\n",
      "[74]\tvalidation_0-logloss:0.50224\n",
      "[75]\tvalidation_0-logloss:0.50214\n",
      "[76]\tvalidation_0-logloss:0.50214\n",
      "[77]\tvalidation_0-logloss:0.50216\n",
      "[78]\tvalidation_0-logloss:0.50206\n",
      "[79]\tvalidation_0-logloss:0.50220\n",
      "[80]\tvalidation_0-logloss:0.50198\n",
      "[81]\tvalidation_0-logloss:0.50190\n",
      "[82]\tvalidation_0-logloss:0.50200\n",
      "[83]\tvalidation_0-logloss:0.50201\n",
      "[84]\tvalidation_0-logloss:0.50188\n",
      "[85]\tvalidation_0-logloss:0.50201\n",
      "[86]\tvalidation_0-logloss:0.50206\n",
      "[87]\tvalidation_0-logloss:0.50176\n",
      "[88]\tvalidation_0-logloss:0.50100\n",
      "[89]\tvalidation_0-logloss:0.50103\n",
      "[90]\tvalidation_0-logloss:0.50103\n",
      "[91]\tvalidation_0-logloss:0.50101\n",
      "[92]\tvalidation_0-logloss:0.50029\n",
      "[93]\tvalidation_0-logloss:0.50044\n",
      "[94]\tvalidation_0-logloss:0.50030\n",
      "[95]\tvalidation_0-logloss:0.49978\n",
      "[96]\tvalidation_0-logloss:0.49966\n",
      "[97]\tvalidation_0-logloss:0.49945\n",
      "[98]\tvalidation_0-logloss:0.49955\n",
      "[99]\tvalidation_0-logloss:0.49946\n",
      "[100]\tvalidation_0-logloss:0.49957\n",
      "[101]\tvalidation_0-logloss:0.49941\n",
      "[102]\tvalidation_0-logloss:0.49947\n",
      "[103]\tvalidation_0-logloss:0.49946\n",
      "[104]\tvalidation_0-logloss:0.49953\n",
      "[105]\tvalidation_0-logloss:0.49957\n",
      "[106]\tvalidation_0-logloss:0.49969\n",
      "[107]\tvalidation_0-logloss:0.49953\n",
      "[108]\tvalidation_0-logloss:0.49938\n",
      "[109]\tvalidation_0-logloss:0.49935\n",
      "[110]\tvalidation_0-logloss:0.49928\n",
      "[111]\tvalidation_0-logloss:0.49934\n",
      "[112]\tvalidation_0-logloss:0.49938\n",
      "[113]\tvalidation_0-logloss:0.49939\n",
      "[114]\tvalidation_0-logloss:0.49944\n",
      "[115]\tvalidation_0-logloss:0.49931\n",
      "[116]\tvalidation_0-logloss:0.49921\n",
      "[117]\tvalidation_0-logloss:0.49906\n",
      "[118]\tvalidation_0-logloss:0.49892\n",
      "[119]\tvalidation_0-logloss:0.49875\n",
      "[120]\tvalidation_0-logloss:0.49875\n",
      "[121]\tvalidation_0-logloss:0.49873\n",
      "[122]\tvalidation_0-logloss:0.49858\n",
      "[123]\tvalidation_0-logloss:0.49863\n",
      "[124]\tvalidation_0-logloss:0.49862\n",
      "[125]\tvalidation_0-logloss:0.49856\n",
      "[126]\tvalidation_0-logloss:0.49842\n",
      "[127]\tvalidation_0-logloss:0.49855\n",
      "[128]\tvalidation_0-logloss:0.49861\n",
      "[129]\tvalidation_0-logloss:0.49869\n",
      "[130]\tvalidation_0-logloss:0.49861\n",
      "[131]\tvalidation_0-logloss:0.49858\n",
      "[132]\tvalidation_0-logloss:0.49858\n",
      "[133]\tvalidation_0-logloss:0.49852\n",
      "[134]\tvalidation_0-logloss:0.49842\n",
      "[135]\tvalidation_0-logloss:0.49834\n",
      "[136]\tvalidation_0-logloss:0.49835\n",
      "[137]\tvalidation_0-logloss:0.49828\n",
      "[138]\tvalidation_0-logloss:0.49833\n",
      "[139]\tvalidation_0-logloss:0.49819\n",
      "[140]\tvalidation_0-logloss:0.49762\n",
      "[141]\tvalidation_0-logloss:0.49739\n",
      "[142]\tvalidation_0-logloss:0.49743\n",
      "[143]\tvalidation_0-logloss:0.49724\n",
      "[144]\tvalidation_0-logloss:0.49736\n",
      "[145]\tvalidation_0-logloss:0.49732\n",
      "[146]\tvalidation_0-logloss:0.49734\n",
      "[147]\tvalidation_0-logloss:0.49741\n",
      "[148]\tvalidation_0-logloss:0.49739\n",
      "[149]\tvalidation_0-logloss:0.49738\n",
      "[150]\tvalidation_0-logloss:0.49725\n",
      "[151]\tvalidation_0-logloss:0.49735\n",
      "[152]\tvalidation_0-logloss:0.49728\n",
      "[153]\tvalidation_0-logloss:0.49728\n",
      "[154]\tvalidation_0-logloss:0.49718\n",
      "[155]\tvalidation_0-logloss:0.49738\n",
      "[156]\tvalidation_0-logloss:0.49727\n",
      "[157]\tvalidation_0-logloss:0.49707\n",
      "[158]\tvalidation_0-logloss:0.49717\n",
      "[159]\tvalidation_0-logloss:0.49719\n",
      "[160]\tvalidation_0-logloss:0.49722\n",
      "[161]\tvalidation_0-logloss:0.49724\n",
      "[162]\tvalidation_0-logloss:0.49732\n",
      "[163]\tvalidation_0-logloss:0.49727\n",
      "[164]\tvalidation_0-logloss:0.49727\n",
      "[165]\tvalidation_0-logloss:0.49727\n",
      "[166]\tvalidation_0-logloss:0.49727\n",
      "[167]\tvalidation_0-logloss:0.49719\n",
      "[168]\tvalidation_0-logloss:0.49727\n",
      "[169]\tvalidation_0-logloss:0.49723\n",
      "[170]\tvalidation_0-logloss:0.49713\n",
      "[171]\tvalidation_0-logloss:0.49723\n",
      "[172]\tvalidation_0-logloss:0.49724\n",
      "[173]\tvalidation_0-logloss:0.49718\n",
      "[174]\tvalidation_0-logloss:0.49697\n",
      "[175]\tvalidation_0-logloss:0.49709\n",
      "[176]\tvalidation_0-logloss:0.49705\n",
      "[177]\tvalidation_0-logloss:0.49699\n",
      "[178]\tvalidation_0-logloss:0.49694\n",
      "[179]\tvalidation_0-logloss:0.49687\n",
      "[180]\tvalidation_0-logloss:0.49692\n",
      "[181]\tvalidation_0-logloss:0.49679\n",
      "[182]\tvalidation_0-logloss:0.49688\n",
      "[183]\tvalidation_0-logloss:0.49688\n",
      "[184]\tvalidation_0-logloss:0.49698\n",
      "[185]\tvalidation_0-logloss:0.49698\n",
      "[186]\tvalidation_0-logloss:0.49696\n",
      "[187]\tvalidation_0-logloss:0.49699\n",
      "[188]\tvalidation_0-logloss:0.49693\n",
      "[189]\tvalidation_0-logloss:0.49668\n",
      "[190]\tvalidation_0-logloss:0.49666\n",
      "[191]\tvalidation_0-logloss:0.49648\n",
      "[192]\tvalidation_0-logloss:0.49647\n",
      "[193]\tvalidation_0-logloss:0.49647\n",
      "[194]\tvalidation_0-logloss:0.49644\n",
      "[195]\tvalidation_0-logloss:0.49644\n",
      "[196]\tvalidation_0-logloss:0.49654\n",
      "[197]\tvalidation_0-logloss:0.49657\n",
      "[198]\tvalidation_0-logloss:0.49650\n",
      "[199]\tvalidation_0-logloss:0.49659\n",
      "\n",
      "Model Evaluation:\n",
      "--------------------------------------------------\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       898\n",
      "           1       0.73      0.81      0.77      1150\n",
      "\n",
      "    accuracy                           0.73      2048\n",
      "   macro avg       0.73      0.72      0.72      2048\n",
      "weighted avg       0.73      0.73      0.73      2048\n",
      "\n",
      "\n",
      "Precision Score (our priority metric):\n",
      "0.7338582677165354\n",
      "\n",
      "Confusion Matrix:\n",
      "[[560 338]\n",
      " [218 932]]\n",
      "Model saved to fake_news_model.joblib\n",
      "Vectorizer saved to tfidf_vectorizer.joblib\n",
      "\n",
      "Testing prediction pipeline:\n",
      "--------------------------------------------------\n",
      "\n",
      "Text: The company exceeded quarterly earnings expectations with a 25% revenue growth.\n",
      "Prediction: False\n",
      "Confidence: 60.97%\n",
      "True probability: 39.03%\n",
      "False probability: 60.97%\n",
      "\n",
      "Text: Government officials deny any involvement in the controversial policy change.\n",
      "Prediction: False\n",
      "Confidence: 70.84%\n",
      "True probability: 29.16%\n",
      "False probability: 70.84%\n",
      "\n",
      "Text: Studies show that the new policy has had mixed results across different regions.\n",
      "Prediction: False\n",
      "Confidence: 63.28%\n",
      "True probability: 36.72%\n",
      "False probability: 63.28%\n",
      "\n",
      "Text: The CEO announced record profits despite market challenges.\n",
      "Prediction: False\n",
      "Confidence: 62.54%\n",
      "True probability: 37.46%\n",
      "False probability: 62.54%\n",
      "\n",
      "Text: Anonymous sources claim massive layoffs are planned for next month.\n",
      "Prediction: False\n",
      "Confidence: 53.62%\n",
      "True probability: 46.38%\n",
      "False probability: 53.62%\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "def main():\n",
    "    try:\n",
    "        # Load dataset\n",
    "        print(\"Loading dataset...\")\n",
    "        df = load_liar_dataset()\n",
    "        \n",
    "        if df is not None:\n",
    "            # Prepare features (now only text features)\n",
    "            print(\"Preparing features...\")\n",
    "            X, tfidf_vectorizer = prepare_features(df)\n",
    "            y = df['label_binary'].values\n",
    "            \n",
    "            # Train model\n",
    "            print(\"Training model...\")\n",
    "            model, X_test, y_test = train_model(X, y)\n",
    "            \n",
    "            # Save model and vectorizer\n",
    "            save_model_and_vectorizer(model, tfidf_vectorizer)\n",
    "            \n",
    "            # Test the pipeline\n",
    "            test_prediction_pipeline(model, tfidf_vectorizer)\n",
    "            \n",
    "            return model, tfidf_vectorizer\n",
    "        \n",
    "        return None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, vectorizer = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
